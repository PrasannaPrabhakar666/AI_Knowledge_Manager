import os
import json
import httpx
import nest_asyncio
from typing import List, Optional
from pydantic import BaseModel, Field
from PyPDF2 import PdfReader
from llama_index.llms.openai import OpenAI
from llama_index.core import Settings
from llama_index.core.program import FunctionCallingProgram
from llama_index.core.extractors import PydanticProgramExtractor

class NodeMetadata(BaseModel):
    Abstract: str = Field(description="A brief, objective summary of the main points or ideas in the text")
    Summary: str = Field(description="A more detailed summary of the text, capturing key points and concepts")
    Top_Questions: List[str] = Field(description="List the most important questions that this text answers or addresses")
    Document_Description: str = Field(description="A concise description of what this document or text is about")
    Intent_or_Purpose: str = Field(description="The main goal or objective of this text or document")
    Target_Audience: List[str] = Field(description="The intended readers or users of this information")
    Tone_Style_Guidelines: List[str] = Field(description="Describe the writing style, tone, and any specific guidelines followed in the text")
    Confidentiality_or_Access_Level: str = Field(description="Indicate the level of confidentiality or who should have access to this information")
    Usage_Guidelines_or_Instructions: str = Field(description="Any specific instructions or guidelines on how to use or interpret this information")
    Contains_Sensitive_Data: bool = Field(description="Indicates whether the text contains any sensitive or confidential information")
    Sensitive_Data_Types: Optional[List[str]] = Field(description="If sensitive data is present, list the types (e.g., PII, financial, medical)")
    Contextual_Relevance: str = Field(description="Explain how this information fits into a broader context or relates to other topics")
    Bias_Indicators: Optional[List[str]] = Field(description="Note any potential biases or subjective viewpoints present in the text")
    Source_Credibility_or_Authority: str = Field(description="Assess the credibility or authority of the source of this information")
    AI_Generated_Content_Flag: bool = Field(description="Indicate if there's any suspicion that this content was generated by AI")
    Relevance_to_Prompt: Optional[str] = Field(description="If applicable, how relevant is this text to a given prompt or query?")

class MetadataExtractor:
    def __init__(self, genai_user, genai_pass, ca_bundle_path):
        nest_asyncio.apply()
        self.http_client = httpx.Client(verify=ca_bundle_path, headers={
            "GENAI_USER": genai_user,
            "GENAI_PASS": genai_pass
        })
        self.llm = OpenAI(temperature=0.1, model="gpt-4", http_client=self.http_client)
        Settings.llm = self.llm
        self.extract_template_str = """
        Analyze the following text chunk and extract the requested metadata. Be as accurate and concise as possible. If a field is not applicable or the information is not present, respond with "N/A".

        Text chunk:
        {text}

        Please extract the following metadata:
        1. Abstract: Provide a brief, objective summary of the main points or ideas in the text.
        2. Summary: Give a more detailed summary of the text, capturing key points and concepts.
        3. Top Questions: List the most important questions that this text answers or addresses.
        4. Document Description: Provide a concise description of what this document or text is about.
        5. Intent or Purpose: State the main goal or objective of this text or document.
        6. Target Audience: Identify the intended readers or users of this information.
        7. Tone/Style Guidelines: Describe the writing style, tone, and any specific guidelines followed in the text.
        8. Confidentiality or Access Level: Indicate the level of confidentiality or who should have access to this information.
        9. Usage Guidelines or Instructions: Note any specific instructions or guidelines on how to use or interpret this information.
        10. Contains Sensitive Data: Indicate whether the text contains any sensitive or confidential information (True/False).
        11. Sensitive Data Types: If sensitive data is present, list the types (e.g., PII, financial, medical).
        12. Contextual Relevance: Explain how this information fits into a broader context or relates to other topics.
        13. Bias Indicators: Note any potential biases or subjective viewpoints present in the text.
        14. Source Credibility or Authority: Assess the credibility or authority of the source of this information.
        15. AI-Generated Content Flag: Indicate if there's any suspicion that this content was generated by AI (True/False).
        16. Relevance to Prompt: If applicable, how relevant is this text to a given prompt or query?

        Based on this analysis, generate a NodeMetadata object with the extracted information.
        """
        self.openai_program = FunctionCallingProgram.from_defaults(
            llm=self.llm,
            output_cls=NodeMetadata,
            prompt_template_str=self.extract_template_str,
            verbose=True,
        )
        self.program_extractor = PydanticProgramExtractor(
            program=self.openai_program,
            input_key="text",
            show_progress=True
        )

    def extract_text_from_pdf(self, pdf_path):
        pdf = PdfReader(pdf_path)
        text = ""
        for page in pdf.pages:
            text += page.extract_text()
        return text

    def chunk_text(self, text, chunk_size, overlap):
        return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size-overlap)]

    def process_pdfs(self, dir_path, chunk_size=1024, overlap=64):
        json_output = {}
        for filename in os.listdir(dir_path):
            if filename.endswith('.pdf'):
                pdf_path = os.path.join(dir_path, filename)
                print(f"Processing {pdf_path}")
                text = self.extract_text_from_pdf(pdf_path)
                chunks = self.chunk_text(text, chunk_size, overlap)
                json_output[filename] = []
                for i, chunk in enumerate(chunks):
                    print(f"Processing chunk {i}: {chunk[:50]}... (Length: {len(chunk)})")
                    if len(chunk) == chunk_size:
                        openai_output = self.openai_program(text=chunk)
                        json_output[filename].append({
                            'chunk_id': str(i),
                            'chunk_text': chunk,
                            'openai_output': openai_output
                        })
        return json_output

class NodeMetadataEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, NodeMetadata):
            return obj.dict()
        return super().default(obj)